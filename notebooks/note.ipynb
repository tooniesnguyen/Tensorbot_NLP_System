{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch import optim\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Who did the first work generally recognized as...   \n",
       "1  What sources was drawn on the formation of the...   \n",
       "2             Who created the Hebbian learning rule?   \n",
       "3            When the first neural network is built?   \n",
       "4           What is the first neural network called?   \n",
       "\n",
       "                                                   1  \n",
       "0        Warren McCulloch and Walter Pitts (1943).\\n  \n",
       "1  knowledge of the basic physiology and function...  \n",
       "2                              Donald Hebb (1949).\\n  \n",
       "3                                            1950.\\n  \n",
       "4                                       The SNARC.\\n  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/AI.csv\", sep=\",\", header= None, skiprows=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who did the first work generally recognized as AI?'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a in df[[1,2]].values:\n",
    "#     print(a[0])\n",
    "#     break\n",
    "\n",
    "pairs_read = df.values.tolist()\n",
    "pairs_read[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(df_filter: list, reverse = False):\n",
    "    '''\n",
    "    The input is two column question and answer\n",
    "    return OOP_QA, pairs (question answer)\n",
    "    '''\n",
    "\n",
    "    print(\"Reading lines...\")\n",
    "    OOP_QA = Lang(\"Q_A\")\n",
    "    return OOP_QA, df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 503 sentence pairs\n",
      "Trimmed to 495 sentence pairs\n",
      "Counting words...\n",
      "Counted words: \n",
      "Total bag of word:  2382\n",
      "['What is Type B strategy?', '\"A Type B strategy ignores moves that look bad']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(dataframe , reverse = False):\n",
    "    '''\n",
    "    Input must be dataframe fillter just two column Q&A\n",
    "    '''\n",
    "    oop_qa, pairs = readLangs(dataframe)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    # Add word to oop to create index2word\n",
    "    for pair in pairs:\n",
    "        oop_qa.addSentence(pair[0])\n",
    "        oop_qa.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words: \")\n",
    "    print(\"Total bag of word: \", oop_qa.n_words)\n",
    "    return oop_qa, pairs\n",
    "\n",
    "oop_qa, pairs_return = prepareData(pairs_read, False)\n",
    "print(random.choice(pairs_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p = 0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True )\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden =self.gru(embedded)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout = 0, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.Wq = nn.LazyLinear(hidden_size, bias = False)\n",
    "        self.Wk = nn.LazyLinear(hidden_size, bias = False)\n",
    "        self.Wv = nn.LazyLinear(1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query, keys, values = None):\n",
    "        if values is None:\n",
    "            values = keys\n",
    "        # Key = values shape \n",
    "        # Ex reduce shape key: (10, 8) -> (10, 1) -> (1, 10)@(10, 8) = (1, 8)\n",
    "        scores = self.Wv(torch.tanh(self.Wq(query) + self.Wk(keys)))\n",
    "        # Chuyển [batc, num rows, num cols (1)] -> [batch, 1, num rows -> num col]\n",
    "        # Mỗi hàng sẽ chứa kết quả của 1 batch không còn mỗi cột nữa\n",
    "        # Hay nói cách khác chuyển đặng trưng từ cột về hàng\n",
    "        '''\n",
    "            Features shape  torch.Size([32, 10, 1])\n",
    "            Scores shape  torch.Size([32, 1, 10])\n",
    "        '''\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, values)\n",
    "\n",
    "        return context, weights\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size, dropout= dropout_p)\n",
    "        # batch_first=True \n",
    "        # ->input và output sẽ có dạng (batch_size, seq_len, features) thay vì (seq_len, batch_size, features) như mặc định\n",
    "        self.gru = nn.GRU(2*hidden_size, hidden_size, batch_first=True) \n",
    "        self.out = nn.LazyLinear(output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input  = torch.empty(batch_size, 1, dtype = torch.long, device = device).fill_(SOS_token)\n",
    "        # print(\"Hidden encoder shape\", encoder_hidden.shape)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, atten_weight = self.forward_step(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Append [1,2,x,.., 10]\n",
    "            # [32, 1, 128],[32,1,128]\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(atten_weight)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach() \n",
    "                \n",
    "        decoder_outputs = self.out(torch.cat(decoder_outputs, dim=1))\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        # Check phải đưa batch lên đầu không\n",
    "        query = hidden.permute(1, 0 ,2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru  = torch.cat((embedded, context), dim = 2)\n",
    "        # print(\"input gru shape \",input_gru.shape, hidden.shape)\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(oop_qa, sentence):\n",
    "    return [oop_qa.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "def tensorFromSentence(oop_qa, sentence):\n",
    "    indexes = indexesFromSentence(oop_qa, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype= torch.long, device = device).reshape(1, -1)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    oop_qa, pairs = prepareData(pairs_read, False)\n",
    "    n = len(pairs)\n",
    "\n",
    "    input_ids = np.zeros((n, MAX_LENGTH), dtype = np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype = np.int32)\n",
    "\n",
    "    for idx, (inp, tgt) in enumerate(pairs):\n",
    "        inp_ids =indexesFromSentence(oop_qa,inp)\n",
    "        tgt_ids =indexesFromSentence(oop_qa,tgt)\n",
    "        \n",
    "        inp_ids.append(EOS_token)\n",
    "        tgt_ids.append(EOS_token)\n",
    "\n",
    "        input_ids[idx, :len(inp_ids)] = inp_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(input_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return oop_qa, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "oop_qa, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(oop_qa.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, oop_qa.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 400, print_every=20, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, oop_qa):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(oop_qa, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(oop_qa.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs_return)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], oop_qa)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> who discovered a complete theorem-proving algorithm for first-order logic in 1965?\n",
      "= J. A. Robinson's\n",
      "\n",
      "< initial pruning space  satisfiable episodic; mechanism concerned sophisticated concerned branching sophisticated sophisticated Complete fit fit concerned branching \"Reduces example branching Goal Complex branching \"Reduces Goal Complex branching \"Reduces Goal\n",
      "\n",
      "> How does logic differs?\n",
      "= Logics differ in their ontological commitments and epistemological commitments.\n",
      "\n",
      "< of representing knowledge base world.\n",
      " <EOS>\n",
      "\n",
      "> What is the right thing?\n",
      "= \"It is expected to maximize goal achievement\n",
      "< \"It is expected to maximize goal achievement <EOS>\n",
      "\n",
      "> What is Five-in-row system?\n",
      "= Five-in-row system is normally is implemented as a board game.\n",
      "\n",
      "< Five-in-row system is higher than by programming its intelligence (AI) problem unary proof they go next.\n",
      " <EOS>\n",
      "\n",
      "> What are the four basic kinds of agent programs that embody the principles underlying almost all intelligent systems?\n",
      "= Simple reflex agents; Model-based reflex agents; Goal-based agents; and Utility-based agents.\n",
      "\n",
      "< Simple reflex agents; Goal-based agents; and Utility-based agents.\n",
      " <EOS>\n",
      "\n",
      "> What task environment makes an agent need not worry about uncertainty?\n",
      "= fully observable and deterministic.\n",
      "\n",
      "< <EOS>\n",
      "\n",
      "> What is semantics?\n",
      "= \"Semantics are the meaning of sentences\n",
      "< \"Semantics are the “solutions.”\n",
      " <EOS>\n",
      "\n",
      "> Who reminded that the field of those broader goals and warned that the subfields were in danger of becoming ends in themselves?\n",
      "= Nils Nilsson (1995)\n",
      "\n",
      "< Nils Nilsson (1995)\n",
      " <EOS>\n",
      "\n",
      "> What are the examples of games of imperfect information?\n",
      "= \"The examples are poker and bridge\n",
      "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "\n",
      "> What kind of advances facilitated the big data phenomenon?\n",
      "= Remarkable advances in computing power and the creation of the World Wide Web.\n",
      "\n",
      "< Remarkable for representing uncertain knowledge bases in computing representing uncertain variables or \"Reduces knowledge.\n",
      " \"Reduces Following Equipment \"Reduces Equipment Corporation Equipment \"Reduces Equipment \"Reduces Equipment \"Reduces Equipment \"Reduces \"Recursive symbol\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "max_len = 1000\n",
    "num_hiddens = 32\n",
    "\n",
    "a = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([         1,          4,         16,         64,        256,       1024,\n",
       "              4096,      16384,      65536,     262144,    1048576,    4194304,\n",
       "          16777216,   67108864,  268435456, 1073741824,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(2, torch.arange(0, num_hiddens, 2, dtype=torch.int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
       "         24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
       "         36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
       "         48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
       "         60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "         72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
       "         84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
       "         96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
       "        108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.,\n",
       "        120., 121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "        132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "        144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154., 155.,\n",
       "        156., 157., 158., 159., 160., 161., 162., 163., 164., 165., 166., 167.,\n",
       "        168., 169., 170., 171., 172., 173., 174., 175., 176., 177., 178., 179.,\n",
       "        180., 181., 182., 183., 184., 185., 186., 187., 188., 189., 190., 191.,\n",
       "        192., 193., 194., 195., 196., 197., 198., 199., 200., 201., 202., 203.,\n",
       "        204., 205., 206., 207., 208., 209., 210., 211., 212., 213., 214., 215.,\n",
       "        216., 217., 218., 219., 220., 221., 222., 223., 224., 225., 226., 227.,\n",
       "        228., 229., 230., 231., 232., 233., 234., 235., 236., 237., 238., 239.,\n",
       "        240., 241., 242., 243., 244., 245., 246., 247., 248., 249., 250., 251.,\n",
       "        252., 253., 254., 255., 256., 257., 258., 259., 260., 261., 262., 263.,\n",
       "        264., 265., 266., 267., 268., 269., 270., 271., 272., 273., 274., 275.,\n",
       "        276., 277., 278., 279., 280., 281., 282., 283., 284., 285., 286., 287.,\n",
       "        288., 289., 290., 291., 292., 293., 294., 295., 296., 297., 298., 299.,\n",
       "        300., 301., 302., 303., 304., 305., 306., 307., 308., 309., 310., 311.,\n",
       "        312., 313., 314., 315., 316., 317., 318., 319., 320., 321., 322., 323.,\n",
       "        324., 325., 326., 327., 328., 329., 330., 331., 332., 333., 334., 335.,\n",
       "        336., 337., 338., 339., 340., 341., 342., 343., 344., 345., 346., 347.,\n",
       "        348., 349., 350., 351., 352., 353., 354., 355., 356., 357., 358., 359.,\n",
       "        360., 361., 362., 363., 364., 365., 366., 367., 368., 369., 370., 371.,\n",
       "        372., 373., 374., 375., 376., 377., 378., 379., 380., 381., 382., 383.,\n",
       "        384., 385., 386., 387., 388., 389., 390., 391., 392., 393., 394., 395.,\n",
       "        396., 397., 398., 399., 400., 401., 402., 403., 404., 405., 406., 407.,\n",
       "        408., 409., 410., 411., 412., 413., 414., 415., 416., 417., 418., 419.,\n",
       "        420., 421., 422., 423., 424., 425., 426., 427., 428., 429., 430., 431.,\n",
       "        432., 433., 434., 435., 436., 437., 438., 439., 440., 441., 442., 443.,\n",
       "        444., 445., 446., 447., 448., 449., 450., 451., 452., 453., 454., 455.,\n",
       "        456., 457., 458., 459., 460., 461., 462., 463., 464., 465., 466., 467.,\n",
       "        468., 469., 470., 471., 472., 473., 474., 475., 476., 477., 478., 479.,\n",
       "        480., 481., 482., 483., 484., 485., 486., 487., 488., 489., 490., 491.,\n",
       "        492., 493., 494., 495., 496., 497., 498., 499., 500., 501., 502., 503.,\n",
       "        504., 505., 506., 507., 508., 509., 510., 511., 512., 513., 514., 515.,\n",
       "        516., 517., 518., 519., 520., 521., 522., 523., 524., 525., 526., 527.,\n",
       "        528., 529., 530., 531., 532., 533., 534., 535., 536., 537., 538., 539.,\n",
       "        540., 541., 542., 543., 544., 545., 546., 547., 548., 549., 550., 551.,\n",
       "        552., 553., 554., 555., 556., 557., 558., 559., 560., 561., 562., 563.,\n",
       "        564., 565., 566., 567., 568., 569., 570., 571., 572., 573., 574., 575.,\n",
       "        576., 577., 578., 579., 580., 581., 582., 583., 584., 585., 586., 587.,\n",
       "        588., 589., 590., 591., 592., 593., 594., 595., 596., 597., 598., 599.,\n",
       "        600., 601., 602., 603., 604., 605., 606., 607., 608., 609., 610., 611.,\n",
       "        612., 613., 614., 615., 616., 617., 618., 619., 620., 621., 622., 623.,\n",
       "        624., 625., 626., 627., 628., 629., 630., 631., 632., 633., 634., 635.,\n",
       "        636., 637., 638., 639., 640., 641., 642., 643., 644., 645., 646., 647.,\n",
       "        648., 649., 650., 651., 652., 653., 654., 655., 656., 657., 658., 659.,\n",
       "        660., 661., 662., 663., 664., 665., 666., 667., 668., 669., 670., 671.,\n",
       "        672., 673., 674., 675., 676., 677., 678., 679., 680., 681., 682., 683.,\n",
       "        684., 685., 686., 687., 688., 689., 690., 691., 692., 693., 694., 695.,\n",
       "        696., 697., 698., 699., 700., 701., 702., 703., 704., 705., 706., 707.,\n",
       "        708., 709., 710., 711., 712., 713., 714., 715., 716., 717., 718., 719.,\n",
       "        720., 721., 722., 723., 724., 725., 726., 727., 728., 729., 730., 731.,\n",
       "        732., 733., 734., 735., 736., 737., 738., 739., 740., 741., 742., 743.,\n",
       "        744., 745., 746., 747., 748., 749., 750., 751., 752., 753., 754., 755.,\n",
       "        756., 757., 758., 759., 760., 761., 762., 763., 764., 765., 766., 767.,\n",
       "        768., 769., 770., 771., 772., 773., 774., 775., 776., 777., 778., 779.,\n",
       "        780., 781., 782., 783., 784., 785., 786., 787., 788., 789., 790., 791.,\n",
       "        792., 793., 794., 795., 796., 797., 798., 799., 800., 801., 802., 803.,\n",
       "        804., 805., 806., 807., 808., 809., 810., 811., 812., 813., 814., 815.,\n",
       "        816., 817., 818., 819., 820., 821., 822., 823., 824., 825., 826., 827.,\n",
       "        828., 829., 830., 831., 832., 833., 834., 835., 836., 837., 838., 839.,\n",
       "        840., 841., 842., 843., 844., 845., 846., 847., 848., 849., 850., 851.,\n",
       "        852., 853., 854., 855., 856., 857., 858., 859., 860., 861., 862., 863.,\n",
       "        864., 865., 866., 867., 868., 869., 870., 871., 872., 873., 874., 875.,\n",
       "        876., 877., 878., 879., 880., 881., 882., 883., 884., 885., 886., 887.,\n",
       "        888., 889., 890., 891., 892., 893., 894., 895., 896., 897., 898., 899.,\n",
       "        900., 901., 902., 903., 904., 905., 906., 907., 908., 909., 910., 911.,\n",
       "        912., 913., 914., 915., 916., 917., 918., 919., 920., 921., 922., 923.,\n",
       "        924., 925., 926., 927., 928., 929., 930., 931., 932., 933., 934., 935.,\n",
       "        936., 937., 938., 939., 940., 941., 942., 943., 944., 945., 946., 947.,\n",
       "        948., 949., 950., 951., 952., 953., 954., 955., 956., 957., 958., 959.,\n",
       "        960., 961., 962., 963., 964., 965., 966., 967., 968., 969., 970., 971.,\n",
       "        972., 973., 974., 975., 976., 977., 978., 979., 980., 981., 982., 983.,\n",
       "        984., 985., 986., 987., 988., 989., 990., 991., 992., 993., 994., 995.,\n",
       "        996., 997., 998., 999.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1000, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nums = [0,0,1]\n",
    "temp_num = nums.copy()\n",
    "for num in nums:\n",
    "    if num == 0:\n",
    "        nums.remove(num)\n",
    "        nums.append(0)\n",
    "\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4076,  0.0295, -0.1874, -0.3984, -0.2571, -0.1063, -0.5304, -0.1125],\n",
       "        [-0.4076,  0.0295, -0.1874, -0.3984, -0.2571, -0.1063, -0.5304, -0.1125],\n",
       "        [-0.4076,  0.0295, -0.1874, -0.3984, -0.2571, -0.1063, -0.5304, -0.1125]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2,3,4)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(norm_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm(4, 0.5)\n",
    "shape = (2, 3, 4)\n",
    "add_norm(torch.ones(shape), torch.ones(shape)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:20:22\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Chuỗi thời gian\n",
    "time_string = \"12:20:22AM\"\n",
    "\n",
    "\n",
    "\n",
    "def timeConversion(s):\n",
    "    # Write your code here\n",
    "    time_convert = lambda h: f\"{h:02d}\"\n",
    "    meridiem = re.findall(\"AM|PM\", s)\n",
    "    hour = int(re.findall(\"^(\\d{2})\", s)[0])\n",
    "    if meridiem[0] == \"PM\":\n",
    "        if hour < 12:\n",
    "            s = re.sub(\"^(\\d{2})\", time_convert(hour+12),s)\n",
    "    else:\n",
    "        if hour >= 12:\n",
    "            s = re.sub(\"^(\\d{2})\", time_convert(hour-12),s)\n",
    "\n",
    "            \n",
    "    return re.findall(\"\\d{2}:\\d{2}:\\d{2}\", s)[0]\n",
    "\n",
    "print(timeConversion(time_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12:20:22']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_string = \"12:20:22PM\"\n",
    "\n",
    "re.findall(\"\\d{2}:\\d{2}:\\d{2}\", time_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0537a1d653c093fb02d1293095f59a9c228f06e915f323afd8901f156f0a590c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
