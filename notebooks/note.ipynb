{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from nltk.tokenize import word_tokenize\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler\n",
    "from torch import optim\n",
    "\n",
    "from io import open\n",
    "import unicodedata\n",
    "import re\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Who did the first work generally recognized as...</td>\n",
       "      <td>Warren McCulloch and Walter Pitts (1943).\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What sources was drawn on the formation of the...</td>\n",
       "      <td>knowledge of the basic physiology and function...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Who created the Hebbian learning rule?</td>\n",
       "      <td>Donald Hebb (1949).\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>When the first neural network is built?</td>\n",
       "      <td>1950.\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What is the first neural network called?</td>\n",
       "      <td>The SNARC.\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Who did the first work generally recognized as...   \n",
       "1  What sources was drawn on the formation of the...   \n",
       "2             Who created the Hebbian learning rule?   \n",
       "3            When the first neural network is built?   \n",
       "4           What is the first neural network called?   \n",
       "\n",
       "                                                   1  \n",
       "0        Warren McCulloch and Walter Pitts (1943).\\n  \n",
       "1  knowledge of the basic physiology and function...  \n",
       "2                              Donald Hebb (1949).\\n  \n",
       "3                                            1950.\\n  \n",
       "4                                       The SNARC.\\n  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/AI.csv\", sep=\",\", header= None, skiprows=1)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Who did the first work generally recognized as AI?'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for a in df[[1,2]].values:\n",
    "#     print(a[0])\n",
    "#     break\n",
    "\n",
    "pairs_read = df.values.tolist()\n",
    "pairs_read[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z!?]+\", r\" \", s)\n",
    "    return s.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 30\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(df_filter: list, reverse = False):\n",
    "    '''\n",
    "    The input is two column question and answer\n",
    "    return OOP_QA, pairs (question answer)\n",
    "    '''\n",
    "\n",
    "    print(\"Reading lines...\")\n",
    "    OOP_QA = Lang(\"Q_A\")\n",
    "    return OOP_QA, df_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 503 sentence pairs\n",
      "Trimmed to 495 sentence pairs\n",
      "Counting words...\n",
      "Counted words: \n",
      "Total bag of word:  2382\n",
      "['What problem do real robots must also deal with in robot navigation?', '\"Their sensor readings and motor controls']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(dataframe , reverse = False):\n",
    "    '''\n",
    "    Input must be dataframe fillter just two column Q&A\n",
    "    '''\n",
    "    oop_qa, pairs = readLangs(dataframe)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    # Add word to oop to create index2word\n",
    "    for pair in pairs:\n",
    "        oop_qa.addSentence(pair[0])\n",
    "        oop_qa.addSentence(pair[1])\n",
    "        \n",
    "    print(\"Counted words: \")\n",
    "    print(\"Total bag of word: \", oop_qa.n_words)\n",
    "    return oop_qa, pairs\n",
    "\n",
    "oop_qa, pairs_return = prepareData(pairs_read, False)\n",
    "print(random.choice(pairs_return))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, dropout_p = 0.1):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True )\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "\n",
    "    def forward(self, input):\n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        output, hidden =self.gru(embedded)\n",
    "        return output, hidden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BahdanauAttention(nn.Module):\n",
    "    def __init__(self, hidden_size, dropout = 0, **kwargs) -> None:\n",
    "        super().__init__()\n",
    "        self.Wq = nn.LazyLinear(hidden_size, bias = False)\n",
    "        self.Wk = nn.LazyLinear(hidden_size, bias = False)\n",
    "        self.Wv = nn.LazyLinear(1, bias=False)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    \n",
    "    def forward(self, query, keys, values = None):\n",
    "        if values is None:\n",
    "            values = keys\n",
    "        # Key = values shape \n",
    "        # Ex reduce shape key: (10, 8) -> (10, 1) -> (1, 10)@(10, 8) = (1, 8)\n",
    "        scores = self.Wv(torch.tanh(self.Wq(query) + self.Wk(keys)))\n",
    "\n",
    "        '''\n",
    "            Features shape  torch.Size([32, 10, 1])\n",
    "            Scores shape  torch.Size([32, 1, 10])\n",
    "        '''\n",
    "        scores = scores.squeeze(2).unsqueeze(1)\n",
    "        weights = F.softmax(scores, dim=-1)\n",
    "        context = torch.bmm(weights, values)\n",
    "\n",
    "        return context, weights\n",
    "    \n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.attention = BahdanauAttention(hidden_size, dropout= dropout_p)\n",
    "        # batch_first=True \n",
    "        self.gru = nn.GRU(2*hidden_size, hidden_size, batch_first=True) \n",
    "        self.out = nn.LazyLinear(output_size)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_p)\n",
    "    \n",
    "    def forward(self, encoder_outputs, encoder_hidden, target_tensor=None):\n",
    "        batch_size = encoder_outputs.size(0)\n",
    "        decoder_input  = torch.empty(batch_size, 1, dtype = torch.long, device = device).fill_(SOS_token)\n",
    "        # print(\"Hidden encoder shape\", encoder_hidden.shape)\n",
    "        decoder_hidden = encoder_hidden\n",
    "        decoder_outputs = []\n",
    "        attentions = []\n",
    "\n",
    "        for i in range(MAX_LENGTH):\n",
    "            decoder_output, decoder_hidden, atten_weight = self.forward_step(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            # Append [1,2,x,.., 10]\n",
    "            # [32, 1, 128],[32,1,128]\n",
    "            decoder_outputs.append(decoder_output)\n",
    "            attentions.append(atten_weight)\n",
    "\n",
    "            if target_tensor is not None:\n",
    "                decoder_input = target_tensor[:, i].unsqueeze(1)\n",
    "\n",
    "            else:\n",
    "                _, topi = decoder_output.topk(1)\n",
    "                decoder_input = topi.squeeze(-1).detach() \n",
    "                \n",
    "        decoder_outputs = self.out(torch.cat(decoder_outputs, dim=1))\n",
    "        decoder_outputs = F.log_softmax(decoder_outputs, dim=-1)\n",
    "        attentions = torch.cat(attentions, dim=1)\n",
    "\n",
    "        return decoder_outputs, decoder_hidden, attentions\n",
    "\n",
    "\n",
    "    def forward_step(self, input, hidden, encoder_outputs):\n",
    "        embedded =  self.dropout(self.embedding(input))\n",
    "\n",
    "        query = hidden.permute(1, 0 ,2)\n",
    "        context, attn_weights = self.attention(query, encoder_outputs)\n",
    "        input_gru  = torch.cat((embedded, context), dim = 2)\n",
    "        # print(\"input gru shape \",input_gru.shape, hidden.shape)\n",
    "        output, hidden = self.gru(input_gru, hidden)\n",
    "        output = self.out(output)\n",
    "        return output, hidden, attn_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(oop_qa, sentence):\n",
    "    return [oop_qa.word2index[word] for word in sentence.split(\" \")]\n",
    "\n",
    "def tensorFromSentence(oop_qa, sentence):\n",
    "    indexes = indexesFromSentence(oop_qa, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype= torch.long, device = device).reshape(1, -1)\n",
    "\n",
    "\n",
    "def get_dataloader(batch_size):\n",
    "    oop_qa, pairs = prepareData(pairs_read, False)\n",
    "    n = len(pairs)\n",
    "\n",
    "    source_ids = np.zeros((n, MAX_LENGTH), dtype = np.int32)\n",
    "    target_ids = np.zeros((n, MAX_LENGTH), dtype = np.int32)\n",
    "\n",
    "    for idx, (src, tgt) in enumerate(pairs):\n",
    "        src_ids =indexesFromSentence(oop_qa,src)\n",
    "        tgt_ids =indexesFromSentence(oop_qa,tgt)\n",
    "        \n",
    "        src_ids.append(EOS_token)\n",
    "        print(\"src_ids is \", src_ids)\n",
    "        tgt_ids.append(EOS_token)\n",
    "\n",
    "        source_ids[idx, :len(src_ids)] = src_ids\n",
    "        target_ids[idx, :len(tgt_ids)] = tgt_ids\n",
    "\n",
    "    train_data = TensorDataset(torch.LongTensor(source_ids).to(device),\n",
    "                               torch.LongTensor(target_ids).to(device))\n",
    "\n",
    "    train_sampler = RandomSampler(train_data)\n",
    "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "    return oop_qa, train_dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(dataloader, encoder, decoder, encoder_optimizer,\n",
    "          decoder_optimizer, criterion):\n",
    "\n",
    "    total_loss = 0\n",
    "    for data in dataloader:\n",
    "        input_tensor, target_tensor = data\n",
    "\n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, _, _ = decoder(encoder_outputs, encoder_hidden, target_tensor)\n",
    "\n",
    "        loss = criterion(\n",
    "            decoder_outputs.view(-1, decoder_outputs.size(-1)),\n",
    "            target_tensor.view(-1)\n",
    "        )\n",
    "        loss.backward()\n",
    "\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    return total_loss / len(dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_dataloader, encoder, decoder, n_epochs, learning_rate=0.001,\n",
    "               print_every=100, plot_every=100):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=learning_rate)\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        loss = train_epoch(train_dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if epoch % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, epoch / n_epochs),\n",
    "                                        epoch, epoch / n_epochs * 100, print_loss_avg))\n",
    "\n",
    "        if epoch % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "Read 503 sentence pairs\n",
      "Trimmed to 495 sentence pairs\n",
      "Counting words...\n",
      "Counted words: \n",
      "Total bag of word:  2382\n",
      "src_ids is  [2, 3, 4, 5, 6, 7, 8, 9, 10, 1]\n",
      "src_ids is  [17, 18, 19, 20, 21, 4, 22, 23, 4, 5, 6, 7, 8, 9, 10, 1]\n",
      "src_ids is  [2, 43, 4, 44, 45, 46, 1]\n",
      "src_ids is  [50, 4, 5, 51, 52, 53, 54, 1]\n",
      "src_ids is  [17, 53, 4, 5, 51, 52, 56, 1]\n",
      "src_ids is  [59, 60, 4, 61, 62, 1]\n",
      "src_ids is  [65, 61, 66, 67, 68, 21, 69, 70, 71, 1]\n",
      "src_ids is  [2, 84, 4, 85, 86, 87, 1]\n",
      "src_ids is  [17, 95, 96, 97, 98, 99, 53, 100, 101, 1]\n",
      "src_ids is  [108, 109, 19, 110, 4, 5, 111, 37, 112, 4, 113, 114, 115, 1]\n",
      "src_ids is  [2, 117, 4, 118, 119, 120, 121, 122, 1]\n",
      "src_ids is  [17, 95, 119, 120, 121, 124, 125, 1]\n",
      "src_ids is  [2, 134, 4, 135, 136, 137, 1]\n",
      "src_ids is  [59, 1]\n",
      "src_ids is  [2, 141, 4, 142, 143, 144, 1]\n",
      "src_ids is  [147, 1]\n",
      "src_ids is  [149, 150, 31, 151, 152, 153, 130, 154, 35, 29, 155, 1]\n",
      "src_ids is  [108, 111, 29, 159, 19, 160, 37, 161, 162, 163, 164, 165, 166, 23, 167, 168, 169, 170, 1]\n",
      "src_ids is  [17, 53, 4, 175, 118, 176, 1]\n",
      "src_ids is  [17, 95, 4, 179, 180, 181, 182, 1]\n",
      "src_ids is  [17, 95, 4, 194, 195, 196, 197, 1]\n",
      "src_ids is  [17, 53, 4, 213, 214, 29, 215, 1]\n",
      "src_ids is  [227, 213, 214, 29, 228, 229, 230, 213, 231, 1]\n",
      "src_ids is  [242, 53, 4, 243, 111, 244, 1]\n",
      "src_ids is  [108, 111, 53, 4, 5, 247, 248, 249, 1]\n",
      "src_ids is  [17, 95, 248, 121, 251, 1]\n",
      "src_ids is  [17, 53, 4, 258, 23, 4, 259, 260, 261, 262, 1]\n",
      "src_ids is  [17, 27, 95, 274, 121, 275, 276, 1]\n",
      "src_ids is  [17, 53, 4, 280, 281, 282, 274, 13, 283, 1]\n",
      "src_ids is  [17, 163, 23, 285, 95, 274, 286, 1]\n",
      "src_ids is  [289, 53, 4, 290, 23, 287, 291, 29, 292, 1]\n",
      "src_ids is  [108, 121, 53, 4, 5, 247, 305, 269, 249, 1]\n",
      "src_ids is  [307, 95, 4, 5, 247, 305, 269, 121, 308, 309, 1]\n",
      "src_ids is  [17, 95, 314, 143, 315, 316, 1]\n",
      "src_ids is  [17, 95, 321, 322, 23, 323, 324, 325, 1]\n",
      "src_ids is  [17, 53, 4, 258, 23, 4, 339, 340, 341, 342, 79, 4, 343, 344, 29, 345, 1]\n",
      "src_ids is  [352, 353, 4, 354, 355, 1]\n",
      "src_ids is  [242, 1]\n",
      "src_ids is  [2, 366, 367, 9, 4, 368, 369, 23, 370, 1]\n",
      "src_ids is  [17, 95, 368, 369, 23, 373, 79, 371, 374, 251, 1]\n",
      "src_ids is  [289, 53, 4, 386, 387, 388, 389, 37, 4, 390, 23, 4, 391, 392, 1]\n",
      "src_ids is  [17, 400, 95, 4, 401, 23, 269, 270, 402, 403, 1]\n",
      "src_ids is  [17, 400, 409, 4, 410, 23, 411, 412, 1]\n",
      "src_ids is  [17, 229, 4, 416, 23, 417, 29, 4, 418, 23, 411, 412, 1]\n",
      "src_ids is  [108, 419, 53, 405, 420, 419, 130, 4, 188, 282, 421, 13, 272, 422, 1]\n",
      "src_ids is  [424, 425, 1]\n",
      "src_ids is  [430, 431, 402, 37, 31, 267, 432, 23, 407, 13, 433, 41, 29, 71, 1]\n",
      "src_ids is  [17, 95, 435, 437, 23, 438, 439, 440, 1]\n",
      "src_ids is  [17, 280, 449, 53, 450, 79, 451, 452, 29, 453, 1]\n",
      "src_ids is  [17, 461, 23, 462, 463, 4, 464, 193, 465, 1]\n",
      "src_ids is  [2, 458, 31, 473, 68, 130, 474, 29, 475, 29, 476, 79, 477, 29, 478, 92, 479, 480, 1]\n",
      "src_ids is  [17, 95, 4, 484, 485, 45, 486, 403, 1]\n",
      "src_ids is  [17, 68, 233, 489, 490, 491, 492, 29, 493, 494, 495, 29, 4, 496, 1]\n",
      "src_ids is  [289, 95, 485, 52, 275, 37, 499, 500, 501, 4, 502, 105, 503, 504, 1]\n",
      "src_ids is  [17, 121, 95, 507, 508, 509, 37, 233, 510, 511, 512, 13, 513, 130, 514, 1]\n",
      "src_ids is  [17, 427, 121, 520, 318, 521, 522, 523, 524, 29, 525, 1]\n",
      "src_ids is  [17, 427, 121, 520, 4, 318, 528, 522, 529, 530, 1]\n",
      "src_ids is  [17, 532, 186, 533, 1]\n",
      "src_ids is  [352, 95, 4, 485, 45, 109, 1]\n",
      "src_ids is  [59, 545, 185, 4, 546, 547, 229, 23, 548, 549, 1]\n",
      "src_ids is  [553, 95, 4, 554, 546, 547, 229, 23, 548, 549, 1]\n",
      "src_ids is  [59, 557, 185, 558, 161, 421, 1]\n",
      "src_ids is  [561, 95, 562, 563, 564, 565, 566, 567, 1]\n",
      "src_ids is  [17, 570, 571, 572, 573, 574, 21, 575, 10, 1]\n",
      "src_ids is  [2, 578, 185, 4, 410, 23, 579, 580, 581, 13, 582, 185, 4, 583, 210, 29, 584, 23, 585, 586, 29, 587, 1]\n",
      "src_ids is  [2, 19, 591, 37, 592, 4, 593, 594, 23, 421, 364, 595, 596, 597, 598, 111, 207, 37, 599, 81, 600, 1]\n",
      "src_ids is  [17, 95, 4, 603, 604, 240, 325, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 607, 1]\n",
      "src_ids is  [17, 4, 615, 616, 617, 403, 1]\n",
      "src_ids is  [17, 53, 405, 618, 616, 620, 1]\n",
      "src_ids is  [424, 131, 1]\n",
      "src_ids is  [17, 186, 572, 632, 633, 21, 405, 618, 634, 1]\n",
      "src_ids is  [289, 427, 53, 639, 37, 640, 1]\n",
      "src_ids is  [289, 186, 572, 644, 4, 645, 646, 37, 647, 23, 405, 427, 648, 1]\n",
      "src_ids is  [17, 53, 4, 653, 21, 645, 282, 105, 13, 654, 1]\n",
      "src_ids is  [2, 661, 37, 662, 185, 663, 664, 665, 333, 4, 64, 53, 4, 664, 266, 572, 666, 667, 1]\n",
      "src_ids is  [561, 1]\n",
      "src_ids is  [17, 95, 4, 669, 604, 240, 670, 671, 1]\n",
      "src_ids is  [17, 186, 4, 606, 23, 677, 678, 679, 1]\n",
      "src_ids is  [17, 53, 4, 653, 23, 689, 92, 690, 1]\n",
      "src_ids is  [17, 53, 4, 700, 282, 701, 13, 702, 1]\n",
      "src_ids is  [17, 706, 707, 708, 1]\n",
      "src_ids is  [289, 572, 713, 632, 185, 405, 622, 714, 715, 1]\n",
      "src_ids is  [17, 95, 405, 721, 677, 622, 533, 1]\n",
      "src_ids is  [17, 53, 726, 727, 1]\n",
      "src_ids is  [17, 53, 732, 733, 1]\n",
      "src_ids is  [17, 572, 186, 233, 9, 4, 735, 23, 726, 736, 185, 573, 737, 29, 421, 53, 738, 739, 1]\n",
      "src_ids is  [17, 744, 572, 186, 747, 21, 726, 727, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 765, 766, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 772, 1]\n",
      "src_ids is  [17, 726, 610, 779, 405, 622, 780, 234, 781, 317, 782, 1]\n",
      "src_ids is  [17, 53, 4, 653, 282, 784, 13, 785, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 792, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 797, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 757, 13, 802, 726, 727, 1]\n",
      "src_ids is  [227, 757, 736, 229, 810, 811, 78, 802, 727, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 814, 130, 185, 607, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 759, 130, 185, 607, 1]\n",
      "src_ids is  [227, 759, 726, 819, 229, 820, 37, 821, 822, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 826, 1]\n",
      "src_ids is  [352, 229, 4, 801, 23, 814, 1]\n",
      "src_ids is  [17, 229, 4, 281, 282, 761, 13, 834, 726, 727, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 761, 13, 834, 726, 727, 1]\n",
      "src_ids is  [17, 95, 31, 763, 841, 842, 726, 610, 486, 403, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 848, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 726, 610, 53, 852, 1]\n",
      "src_ids is  [17, 53, 405, 857, 23, 751, 749, 13, 763, 726, 858, 1]\n",
      "src_ids is  [17, 53, 405, 857, 23, 765, 749, 13, 842, 726, 858, 1]\n",
      "src_ids is  [17, 461, 23, 726, 610, 722, 205, 4, 864, 865, 1]\n",
      "src_ids is  [17, 53, 405, 622, 867, 1]\n",
      "src_ids is  [17, 53, 4, 622, 870, 1]\n",
      "src_ids is  [17, 4, 875, 95, 37, 31, 876, 1]\n",
      "src_ids is  [17, 229, 4, 877, 25, 878, 23, 622, 879, 185, 112, 4, 880, 881, 882, 799, 132, 883, 1]\n",
      "src_ids is  [17, 95, 201, 885, 730, 533, 1]\n",
      "src_ids is  [17, 95, 894, 895, 479, 403, 1]\n",
      "src_ids is  [17, 53, 4, 396, 131, 13, 898, 400, 130, 201, 885, 607, 1]\n",
      "src_ids is  [289, 186, 31, 201, 885, 905, 906, 92, 907, 908, 1]\n",
      "src_ids is  [17, 53, 388, 910, 23, 911, 201, 885, 730, 37, 909, 81, 912, 1]\n",
      "src_ids is  [17, 461, 23, 24, 53, 915, 29, 916, 917, 885, 918, 394, 769, 706, 9, 829, 919, 920, 1]\n",
      "src_ids is  [289, 4, 706, 317, 299, 4, 318, 921, 501, 829, 29, 917, 885, 622, 186, 205, 922, 1]\n",
      "src_ids is  [17, 95, 4, 24, 317, 926, 4, 318, 927, 53, 56, 1]\n",
      "src_ids is  [17, 53, 929, 109, 29, 917, 885, 607, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 917, 885, 607, 1]\n",
      "src_ids is  [289, 928, 109, 13, 929, 109, 27, 29, 917, 885, 607, 1]\n",
      "src_ids is  [108, 933, 29, 917, 885, 618, 934, 53, 935, 1]\n",
      "src_ids is  [17, 95, 4, 917, 885, 618, 938, 23, 4, 776, 318, 939, 940, 1]\n",
      "src_ids is  [17, 95, 944, 706, 233, 37, 945, 1]\n",
      "src_ids is  [289, 31, 949, 622, 950, 951, 396, 952, 1]\n",
      "src_ids is  [227, 956, 13, 957, 958, 549, 4, 484, 959, 960, 1]\n",
      "src_ids is  [17, 713, 967, 787, 4, 394, 959, 27, 13, 4, 968, 290, 650, 229, 29, 969, 1]\n",
      "src_ids is  [17, 95, 31, 959, 27, 233, 973, 974, 229, 975, 976, 1]\n",
      "src_ids is  [17, 95, 31, 959, 27, 233, 973, 974, 229, 980, 581, 185, 4, 622, 186, 981, 101, 1]\n",
      "src_ids is  [289, 186, 572, 632, 989, 317, 31, 677, 990, 607, 1]\n",
      "src_ids is  [17, 713, 967, 787, 405, 622, 992, 405, 993, 959, 867, 1]\n",
      "src_ids is  [17, 53, 996, 29, 990, 867, 1]\n",
      "src_ids is  [17, 53, 4, 1000, 130, 622, 37, 1001, 1]\n",
      "src_ids is  [17, 53, 4, 1010, 1011, 130, 31, 45, 607, 1]\n",
      "src_ids is  [17, 95, 4, 45, 1017, 29, 4, 1011, 130, 31, 45, 622, 533, 1]\n",
      "src_ids is  [17, 95, 4, 290, 1017, 29, 4, 1011, 130, 31, 45, 622, 533, 1]\n",
      "src_ids is  [17, 95, 4, 1021, 29, 4, 1011, 130, 31, 45, 622, 533, 1]\n",
      "src_ids is  [227, 1021, 53, 127, 130, 31, 45, 607, 1]\n",
      "src_ids is  [17, 95, 4, 240, 1032, 29, 4, 1011, 130, 31, 45, 622, 533, 1]\n",
      "src_ids is  [17, 713, 967, 787, 405, 622, 53, 1037, 37, 1038, 31, 1039, 13, 233, 491, 1040, 1041, 685, 29, 4, 1042, 1043, 1]\n",
      "src_ids is  [17, 53, 1047, 973, 572, 229, 219, 37, 207, 31, 885, 1048, 238, 31, 959, 867, 1]\n",
      "src_ids is  [17, 95, 4, 290, 1050, 1051, 933, 23, 4, 1052, 616, 1053, 1]\n",
      "src_ids is  [289, 186, 572, 1060, 4, 1061, 23, 726, 736, 29, 658, 1062, 1]\n",
      "src_ids is  [17, 95, 31, 328, 622, 1048, 185, 789, 298, 1064, 1065, 685, 1066, 533, 1]\n",
      "src_ids is  [17, 1070, 29, 405, 795, 1071, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 1075, 6, 298, 795, 1076, 1]\n",
      "src_ids is  [17, 95, 31, 1079, 1080, 533, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 1075, 6, 298, 1079, 1076, 1]\n",
      "src_ids is  [17, 1070, 29, 31, 1087, 1071, 1]\n",
      "src_ids is  [50, 572, 780, 4, 1087, 1071, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 1075, 6, 298, 1087, 1076, 1]\n",
      "src_ids is  [289, 223, 13, 45, 921, 1099, 37, 4, 1100, 468, 23, 4, 1080, 23, 405, 618, 858, 1]\n",
      "src_ids is  [289, 186, 572, 1104, 4, 1105, 23, 1100, 1061, 23, 622, 736, 816, 1106, 658, 1107, 1]\n",
      "src_ids is  [17, 1070, 29, 31, 1112, 1071, 1]\n",
      "src_ids is  [17, 1070, 29, 31, 1117, 1071, 1]\n",
      "src_ids is  [1121, 1061, 229, 396, 314, 986, 1122, 13, 706, 1123, 1]\n",
      "src_ids is  [17, 1126, 1127, 573, 967, 319, 1112, 1076, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 106, 607, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 1133, 1]\n",
      "src_ids is  [17, 1061, 233, 1137, 730, 1138, 1]\n",
      "src_ids is  [17, 1070, 37, 1141, 1142, 1]\n",
      "src_ids is  [17, 1070, 37, 1146, 1142, 1]\n",
      "src_ids is  [17, 53, 4, 1147, 106, 1148, 1]\n",
      "src_ids is  [17, 405, 622, 95, 29, 944, 1153, 1154, 1]\n",
      "src_ids is  [289, 95, 4, 581, 695, 29, 405, 618, 944, 1153, 1154, 1]\n",
      "src_ids is  [17, 405, 622, 95, 29, 240, 1153, 1154, 1]\n",
      "src_ids is  [17, 405, 622, 95, 29, 217, 1154, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 1170, 130, 106, 607, 1]\n",
      "src_ids is  [17, 405, 622, 95, 29, 1172, 1154, 1]\n",
      "src_ids is  [561, 53, 4, 1170, 29, 31, 765, 749, 1]\n",
      "src_ids is  [17, 1174, 121, 53, 79, 4, 1175, 1176, 1]\n",
      "src_ids is  [1121, 1179, 53, 396, 1180, 130, 31, 106, 622, 1]\n",
      "src_ids is  [289, 53, 4, 1170, 29, 31, 751, 749, 238, 1182, 858, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 4, 769, 1190, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 4, 1007, 1192, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 4, 944, 125, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 928, 109, 37, 106, 607, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 626, 1194, 867, 1]\n",
      "src_ids is  [352, 53, 4, 606, 23, 31, 217, 1196, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 405, 1199, 1200, 1]\n",
      "src_ids is  [17, 53, 4, 570, 1203, 23, 648, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 1206, 1]\n",
      "src_ids is  [289, 186, 572, 632, 405, 1210, 53, 1211, 1]\n",
      "src_ids is  [17, 713, 967, 787, 572, 1218, 853, 4, 1219, 37, 1220, 1221, 1222, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 1224, 1225, 1]\n",
      "src_ids is  [289, 186, 1230, 549, 31, 1224, 1225, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 1235, 1225, 1]\n",
      "src_ids is  [17, 53, 31, 1239, 318, 1225, 1]\n",
      "src_ids is  [17, 730, 186, 233, 37, 1248, 29, 1244, 29, 31, 1239, 318, 1225, 1]\n",
      "src_ids is  [17, 1251, 238, 1252, 1253, 233, 29, 31, 1239, 318, 1225, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 31, 1239, 318, 1225, 1]\n",
      "src_ids is  [17, 53, 31, 1259, 1260, 1]\n",
      "src_ids is  [17, 53, 31, 1264, 1225, 1]\n",
      "src_ids is  [17, 53, 4, 1266, 1267, 240, 1268, 1]\n",
      "src_ids is  [17, 95, 31, 1273, 1274, 240, 316, 1]\n",
      "src_ids is  [17, 95, 31, 1273, 1274, 240, 1280, 403, 1]\n",
      "src_ids is  [289, 95, 4, 1273, 1274, 240, 205, 1283, 1]\n",
      "src_ids is  [17, 53, 4, 653, 23, 1289, 1290, 92, 1099, 837, 1291, 1]\n",
      "src_ids is  [17, 240, 233, 391, 1294, 672, 1295, 821, 298, 29, 1289, 1296, 1]\n",
      "src_ids is  [1301, 973, 95, 4, 1302, 1303, 1304, 23, 1102, 1248, 1305, 9, 1306, 1307, 79, 31, 1289, 853, 1308, 1050, 1309, 1310, 1]\n",
      "src_ids is  [17, 53, 1312, 1313, 1]\n",
      "src_ids is  [17, 53, 4, 606, 23, 217, 1314, 1]\n",
      "src_ids is  [17, 95, 31, 1317, 29, 31, 217, 1318, 1319, 403, 1]\n",
      "src_ids is  [17, 95, 405, 1321, 29, 31, 217, 1318, 1319, 403, 1]\n",
      "src_ids is  [17, 95, 4, 1322, 29, 31, 217, 1318, 1319, 403, 1]\n",
      "src_ids is  [17, 53, 4, 1324, 23, 4, 769, 1198, 92, 4, 217, 1325, 1]\n",
      "src_ids is  [17, 53, 4, 1324, 23, 4, 217, 1318, 92, 4, 769, 1190, 1]\n",
      "src_ids is  [17, 53, 4, 1135, 23, 1330, 31, 1331, 1]\n",
      "src_ids is  [1333, 252, 53, 31, 1334, 1317, 23, 1335, 1]\n",
      "src_ids is  [17, 53, 4, 1337, 23, 1133, 1]\n",
      "src_ids is  [289, 186, 572, 632, 31, 1317, 53, 1345, 1]\n",
      "src_ids is  [17, 53, 1349, 1133, 1]\n",
      "src_ids is  [17, 53, 1331, 1]\n",
      "src_ids is  [17, 53, 4, 1357, 23, 31, 1331, 1]\n",
      "src_ids is  [17, 53, 1358, 1]\n",
      "src_ids is  [17, 229, 4, 570, 459, 21, 31, 1361, 1]\n",
      "src_ids is  [17, 53, 31, 1372, 1358, 1]\n",
      "src_ids is  [307, 95, 31, 1372, 1373, 573, 205, 1376, 1]\n",
      "src_ids is  [17, 53, 31, 1378, 1379, 1358, 1]\n",
      "src_ids is  [307, 95, 31, 1382, 1373, 573, 205, 1376, 1]\n",
      "src_ids is  [17, 53, 31, 1384, 1385, 1358, 1]\n",
      "src_ids is  [307, 95, 31, 1388, 1373, 573, 205, 1376, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 1390, 1131, 29, 31, 1133, 1]\n",
      "src_ids is  [67, 53, 4, 570, 1392, 787, 1390, 1131, 1393, 29, 31, 1133, 1]\n",
      "src_ids is  [17, 722, 205, 1395, 29, 4, 1133, 1]\n",
      "src_ids is  [17, 570, 214, 186, 205, 534, 37, 1398, 1399, 1291, 1]\n",
      "src_ids is  [17, 53, 31, 1410, 1133, 1]\n",
      "src_ids is  [17, 53, 31, 1412, 1133, 1]\n",
      "src_ids is  [17, 53, 405, 857, 23, 1410, 217, 1314, 1]\n",
      "src_ids is  [17, 229, 4, 505, 214, 21, 405, 1415, 1416, 1]\n",
      "src_ids is  [17, 95, 1424, 651, 1425, 21, 405, 1426, 1416, 1]\n",
      "src_ids is  [17, 95, 1418, 1429, 651, 1425, 21, 405, 1426, 1416, 1]\n",
      "src_ids is  [17, 95, 1420, 1432, 651, 1425, 21, 405, 1426, 1416, 1]\n",
      "src_ids is  [17, 95, 1422, 1432, 651, 1425, 21, 405, 1426, 1416, 1]\n",
      "src_ids is  [17, 461, 23, 217, 153, 713, 205, 1439, 1]\n",
      "src_ids is  [17, 505, 214, 21, 405, 1415, 290, 229, 1442, 298, 1024, 37, 491, 650, 23, 4, 240, 1443, 1]\n",
      "src_ids is  [17, 1083, 186, 572, 549, 29, 1444, 4, 1432, 23, 405, 1314, 1]\n",
      "src_ids is  [17, 53, 405, 1141, 217, 1446, 1]\n",
      "src_ids is  [17, 53, 1451, 867, 1]\n",
      "src_ids is  [227, 4, 153, 53, 230, 1455, 1]\n",
      "src_ids is  [17, 53, 1461, 1133, 1]\n",
      "src_ids is  [17, 53, 1467, 1]\n",
      "src_ids is  [17, 53, 1469, 1]\n",
      "src_ids is  [17, 53, 4, 1472, 23, 1461, 1133, 1]\n",
      "src_ids is  [17, 53, 4, 1474, 23, 1461, 1133, 1]\n",
      "src_ids is  [17, 53, 405, 1477, 1478, 1]\n",
      "src_ids is  [17, 53, 31, 1482, 1]\n",
      "src_ids is  [1430, 1486, 217, 126, 1487, 1]\n",
      "src_ids is  [17, 95, 4, 1489, 298, 1486, 217, 1490, 1491, 1]\n",
      "src_ids is  [17, 53, 1493, 1494, 1]\n",
      "src_ids is  [17, 53, 1496, 1041, 1133, 1]\n",
      "src_ids is  [108, 1501, 982, 1496, 1041, 1133, 1]\n",
      "src_ids is  [17, 53, 1503, 1133, 1]\n",
      "src_ids is  [17, 53, 1505, 1133, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 405, 1505, 217, 1314, 1]\n",
      "src_ids is  [17, 53, 1506, 1133, 1]\n",
      "src_ids is  [17, 53, 1509, 1461, 1133, 1]\n",
      "src_ids is  [17, 53, 4, 1105, 23, 1509, 1461, 1133, 1]\n",
      "src_ids is  [17, 53, 1518, 1349, 1133, 1]\n",
      "src_ids is  [17, 53, 1523, 1133, 1]\n",
      "src_ids is  [289, 37, 1220, 856, 1530, 1]\n",
      "src_ids is  [289, 233, 1534, 217, 1535, 867, 1]\n",
      "src_ids is  [1539, 1534, 217, 1535, 1540, 1]\n",
      "src_ids is  [17, 229, 4, 1542, 23, 1534, 217, 1142, 1]\n",
      "src_ids is  [17, 53, 1549, 217, 1314, 1]\n",
      "src_ids is  [227, 1554, 1555, 53, 230, 1508, 1534, 1133, 1]\n",
      "src_ids is  [17, 53, 4, 1474, 23, 1554, 1564, 1]\n",
      "src_ids is  [17, 53, 31, 1534, 1568, 1]\n",
      "src_ids is  [17, 53, 31, 1575, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 1580, 1]\n",
      "src_ids is  [17, 53, 784, 1554, 1564, 1]\n",
      "src_ids is  [17, 53, 1591, 1554, 1564, 1]\n",
      "src_ids is  [17, 53, 1597, 1554, 1564, 1]\n",
      "src_ids is  [289, 37, 1459, 31, 492, 1554, 1564, 1]\n",
      "src_ids is  [17, 53, 1605, 1606, 1]\n",
      "src_ids is  [17, 53, 1606, 1]\n",
      "src_ids is  [17, 53, 1534, 1523, 1133, 1]\n",
      "src_ids is  [289, 95, 4, 1534, 1523, 217, 1628, 1]\n",
      "src_ids is  [17, 53, 1633, 1634, 1]\n",
      "src_ids is  [17, 53, 1641, 1314, 1]\n",
      "src_ids is  [50, 53, 4, 1641, 153, 1643, 1]\n",
      "src_ids is  [17, 229, 1647, 1648, 231, 1]\n",
      "src_ids is  [17, 53, 31, 1655, 1192, 1]\n",
      "src_ids is  [17, 53, 31, 1658, 1225, 1]\n",
      "src_ids is  [17, 229, 1660, 217, 1142, 1]\n",
      "src_ids is  [17, 229, 1664, 217, 1142, 1]\n",
      "src_ids is  [289, 53, 405, 1664, 217, 240, 1666, 1]\n",
      "src_ids is  [17, 53, 1670, 1671, 1]\n",
      "src_ids is  [17, 229, 1678, 1679, 1]\n",
      "src_ids is  [17, 53, 4, 1203, 23, 1682, 1683, 1]\n",
      "src_ids is  [17, 53, 1583, 1688, 1]\n",
      "src_ids is  [17, 229, 1670, 727, 1]\n",
      "src_ids is  [17, 53, 405, 1694, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 861, 185, 1697, 405, 1017, 23, 1698, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 861, 23, 1703, 1704, 1]\n",
      "src_ids is  [352, 53, 1707, 1708, 1]\n",
      "src_ids is  [352, 53, 1711, 1]\n",
      "src_ids is  [17, 229, 4, 1717, 141, 1718, 23, 31, 1719, 1]\n",
      "src_ids is  [17, 53, 31, 1720, 1721, 1]\n",
      "src_ids is  [17, 53, 1720, 125, 1]\n",
      "src_ids is  [17, 53, 31, 959, 867, 1]\n",
      "src_ids is  [17, 229, 4, 272, 1731, 23, 31, 959, 867, 1]\n",
      "src_ids is  [17, 53, 31, 769, 1198, 1733, 1]\n",
      "src_ids is  [50, 233, 572, 549, 1735, 1133, 1]\n",
      "src_ids is  [17, 53, 1737, 1]\n",
      "src_ids is  [17, 53, 4, 1735, 217, 1314, 1]\n",
      "src_ids is  [1746, 4, 1735, 217, 153, 1747, 1]\n",
      "src_ids is  [17, 53, 4, 829, 1432, 130, 4, 1735, 217, 1314, 1]\n",
      "src_ids is  [17, 53, 1754, 252, 1446, 1]\n",
      "src_ids is  [17, 53, 1754, 1335, 1446, 1]\n",
      "src_ids is  [17, 53, 4, 653, 282, 4, 1754, 252, 1185, 13, 1754, 1335, 1446, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 861, 298, 1754, 252, 1446, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 861, 298, 1754, 1335, 1185, 1]\n",
      "src_ids is  [17, 53, 1764, 1765, 1]\n",
      "src_ids is  [227, 572, 549, 1770, 1771, 1318, 1133, 1]\n",
      "src_ids is  [17, 229, 1777, 1778, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 784, 1778, 1]\n",
      "src_ids is  [17, 229, 751, 1788, 1778, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 751, 1788, 1778, 1]\n",
      "src_ids is  [17, 229, 784, 724, 749, 1778, 1]\n",
      "src_ids is  [17, 229, 4, 801, 23, 784, 724, 749, 1778, 1]\n",
      "src_ids is  [50, 53, 1770, 1771, 217, 1805, 1]\n",
      "src_ids is  [17, 53, 4, 1806, 23, 1772, 1133, 1]\n",
      "src_ids is  [17, 53, 4, 1806, 23, 1770, 1771, 1133, 1]\n",
      "src_ids is  [17, 53, 1812, 1]\n",
      "src_ids is  [17, 53, 31, 1816, 1086, 1225, 1]\n",
      "src_ids is  [17, 229, 4, 1011, 23, 31, 1816, 1086, 1225, 1]\n",
      "src_ids is  [17, 53, 31, 1823, 238, 1752, 1824, 1]\n",
      "src_ids is  [17, 53, 31, 151, 1824, 1]\n",
      "src_ids is  [17, 53, 31, 1170, 37, 31, 1829, 1]\n",
      "src_ids is  [17, 53, 31, 724, 1824, 1]\n",
      "src_ids is  [17, 53, 31, 724, 1200, 1]\n",
      "src_ids is  [227, 233, 572, 117, 31, 240, 9, 31, 1829, 1]\n",
      "src_ids is  [17, 229, 1840, 1841, 1]\n",
      "src_ids is  [17, 53, 1844, 1845, 1]\n",
      "src_ids is  [17, 53, 31, 1573, 1845, 1]\n",
      "src_ids is  [17, 53, 1816, 1851, 1]\n",
      "src_ids is  [17, 53, 1853, 1]\n",
      "src_ids is  [17, 53, 1859, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 153, 185, 1862, 1863, 1864, 1]\n",
      "src_ids is  [17, 186, 1131, 1867, 533, 1]\n",
      "src_ids is  [17, 53, 1873, 1]\n",
      "src_ids is  [17, 186, 1878, 1451, 533, 1]\n",
      "src_ids is  [17, 186, 4, 1884, 1451, 533, 1]\n",
      "src_ids is  [17, 53, 4, 1888, 23, 1889, 1314, 1]\n",
      "src_ids is  [17, 53, 31, 1894, 1895, 1]\n",
      "src_ids is  [17, 1070, 37, 4, 153, 973, 535, 1752, 1651, 53, 1900, 1]\n",
      "src_ids is  [17, 53, 1816, 1901, 1]\n",
      "src_ids is  [289, 186, 1905, 205, 1906, 1]\n",
      "src_ids is  [17, 53, 31, 1910, 1911, 1]\n",
      "src_ids is  [17, 53, 31, 1318, 1914, 1]\n",
      "src_ids is  [17, 53, 4, 857, 23, 4, 1919, 23, 31, 1318, 1920, 1]\n",
      "src_ids is  [17, 53, 405, 1923, 1]\n",
      "src_ids is  [17, 53, 405, 1928, 1]\n",
      "src_ids is  [17, 1517, 722, 1929, 1933, 1]\n",
      "src_ids is  [17, 53, 4, 1939, 392, 1]\n",
      "src_ids is  [17, 53, 1944, 1]\n",
      "src_ids is  [17, 53, 1946, 1]\n",
      "src_ids is  [17, 53, 181, 1950, 1]\n",
      "src_ids is  [50, 53, 31, 1957, 1960, 1]\n",
      "src_ids is  [50, 53, 31, 1957, 1962, 1]\n",
      "src_ids is  [17, 53, 1964, 1]\n",
      "src_ids is  [17, 233, 4, 153, 233, 29, 1969, 1970, 1]\n",
      "src_ids is  [17, 53, 31, 1972, 1973, 1]\n",
      "src_ids is  [17, 53, 31, 1978, 1979, 1]\n",
      "src_ids is  [17, 53, 1978, 1851, 1]\n",
      "src_ids is  [17, 229, 1988, 1989, 1]\n",
      "src_ids is  [17, 53, 4, 1995, 1996, 1225, 1]\n",
      "src_ids is  [289, 53, 24, 1998, 1]\n",
      "src_ids is  [227, 233, 132, 730, 780, 2002, 1]\n",
      "src_ids is  [289, 53, 31, 1080, 143, 2003, 1]\n",
      "src_ids is  [227, 53, 4, 700, 23, 2005, 282, 1931, 53, 2006, 1]\n",
      "src_ids is  [17, 53, 2009, 1928, 1]\n",
      "src_ids is  [17, 229, 151, 1142, 1]\n",
      "src_ids is  [17, 53, 34, 2014, 1]\n",
      "src_ids is  [17, 186, 34, 35, 533, 1]\n",
      "src_ids is  [17, 229, 1929, 2021, 1]\n",
      "src_ids is  [17, 53, 4, 2024, 46, 1]\n",
      "src_ids is  [17, 229, 4, 1639, 223, 74, 130, 24, 2025, 29, 2030, 2031, 1]\n",
      "src_ids is  [17, 53, 31, 1948, 769, 2034, 1]\n",
      "src_ids is  [17, 233, 770, 2040, 1632, 23, 1948, 769, 2036, 2041, 1]\n",
      "src_ids is  [289, 994, 1497, 31, 1948, 622, 186, 205, 2043, 79, 2044, 2045, 1]\n",
      "src_ids is  [227, 95, 34, 35, 233, 234, 235, 37, 736, 23, 2048, 2049, 1]\n",
      "src_ids is  [289, 722, 24, 1080, 2053, 2054, 1]\n",
      "src_ids is  [289, 95, 35, 2057, 1]\n",
      "src_ids is  [17, 53, 4, 653, 29, 34, 35, 13, 154, 2014, 1]\n",
      "src_ids is  [17, 53, 4, 2067, 23, 34, 35, 13, 154, 2014, 1]\n",
      "src_ids is  [289, 95, 4, 2070, 29, 212, 2071, 63, 2020, 798, 1611, 63, 34, 35, 13, 154, 2014, 1]\n",
      "src_ids is  [17, 95, 4, 2004, 23, 154, 35, 2079, 1]\n",
      "src_ids is  [352, 95, 31, 570, 318, 1]\n",
      "src_ids is  [50, 53, 405, 795, 1957, 2083, 1]\n",
      "src_ids is  [17, 186, 2089, 2090, 533, 1]\n",
      "src_ids is  [17, 53, 4, 1135, 23, 2092, 31, 24, 1938, 29, 154, 2014, 1]\n",
      "src_ids is  [17, 53, 10, 1]\n",
      "src_ids is  [17, 233, 4, 2103, 23, 427, 2104, 1]\n",
      "src_ids is  [17, 53, 4, 61, 2106, 1]\n",
      "src_ids is  [2110, 67, 2111, 186, 82, 205, 2112, 37, 853, 2113, 4, 1721, 1]\n",
      "src_ids is  [17, 2114, 1183, 4, 427, 2115, 1]\n",
      "src_ids is  [17, 229, 4, 2118, 581, 23, 427, 2119, 1]\n",
      "src_ids is  [17, 53, 2121, 1]\n",
      "src_ids is  [17, 331, 23, 223, 229, 2125, 1]\n",
      "src_ids is  [17, 53, 2127, 2121, 1]\n",
      "src_ids is  [17, 53, 2131, 2121, 1]\n",
      "src_ids is  [17, 53, 2134, 2121, 1]\n",
      "src_ids is  [17, 53, 2140, 2141, 1]\n",
      "src_ids is  [289, 2097, 2145, 722, 2146, 1]\n",
      "src_ids is  [17, 1821, 2152, 23, 1559, 233, 572, 780, 37, 207, 29, 2153, 2154, 1]\n",
      "src_ids is  [17, 53, 2156, 1]\n",
      "src_ids is  [17, 53, 2161, 2162, 1]\n",
      "src_ids is  [17, 53, 2165, 2166, 1]\n",
      "src_ids is  [17, 53, 677, 634, 1]\n",
      "src_ids is  [17, 53, 4, 2167, 2169, 1]\n",
      "src_ids is  [17, 229, 4, 1542, 23, 2171, 427, 9, 677, 607, 1]\n",
      "src_ids is  [17, 229, 4, 2172, 2173, 185, 427, 2174, 1]\n",
      "src_ids is  [17, 53, 2179, 10, 1]\n",
      "src_ids is  [17, 233, 4, 2185, 1865, 2186, 2104, 1]\n",
      "src_ids is  [352, 53, 4, 700, 1584, 427, 1]\n",
      "src_ids is  [17, 229, 4, 1542, 23, 10, 1]\n",
      "src_ids is  [17, 229, 4, 2192, 23, 10, 1]\n",
      "src_ids is  [17, 53, 2002, 1]\n",
      "src_ids is  [17, 229, 4, 2197, 23, 2198, 1]\n",
      "src_ids is  [17, 53, 2056, 2002, 1]\n",
      "src_ids is  [17, 53, 2203, 2204, 1]\n",
      "src_ids is  [17, 53, 1451, 2198, 1]\n",
      "src_ids is  [17, 53, 2213, 2002, 1]\n",
      "src_ids is  [17, 53, 2216, 1]\n",
      "src_ids is  [17, 53, 1948, 1071, 1]\n",
      "src_ids is  [17, 2222, 186, 1948, 1080, 205, 794, 2223, 1]\n",
      "src_ids is  [17, 53, 2225, 1]\n",
      "src_ids is  [17, 53, 2228, 2229, 1]\n",
      "src_ids is  [17, 233, 4, 2235, 538, 2236, 2237, 1]\n",
      "src_ids is  [17, 229, 4, 1542, 23, 2235, 46, 1]\n",
      "src_ids is  [17, 229, 4, 2192, 23, 2235, 46, 1]\n",
      "src_ids is  [17, 53, 2244, 2245, 1]\n",
      "src_ids is  [17, 53, 2251, 269, 249, 1]\n",
      "src_ids is  [17, 233, 4, 166, 804, 130, 269, 121, 2104, 1]\n",
      "src_ids is  [17, 233, 4, 1102, 994, 2259, 1]\n",
      "src_ids is  [17, 53, 2033, 2264, 1]\n",
      "src_ids is  [17, 53, 4, 431, 1185, 23, 2033, 1985, 2121, 1]\n",
      "src_ids is  [17, 95, 4, 2033, 1985, 2267, 403, 1]\n",
      "src_ids is  [17, 53, 1764, 2264, 1]\n",
      "src_ids is  [17, 53, 4, 431, 1185, 23, 1764, 1985, 2121, 1]\n",
      "src_ids is  [17, 95, 4, 1764, 1985, 2267, 403, 1]\n",
      "src_ids is  [17, 53, 24, 2270, 1]\n",
      "src_ids is  [17, 53, 24, 2274, 1]\n",
      "src_ids is  [17, 53, 24, 2270, 1]\n",
      "src_ids is  [17, 53, 2280, 249, 1]\n",
      "src_ids is  [17, 53, 1133, 1]\n",
      "src_ids is  [17, 229, 4, 2287, 23, 1133, 1]\n",
      "src_ids is  [17, 53, 2289, 1]\n",
      "src_ids is  [17, 53, 2291, 2292, 1]\n",
      "src_ids is  [17, 53, 2295, 2292, 1]\n",
      "src_ids is  [17, 53, 2299, 2300, 1]\n",
      "src_ids is  [17, 53, 2301, 1225, 1]\n",
      "src_ids is  [2304, 4, 2111, 130, 2305, 1]\n",
      "src_ids is  [17, 53, 766, 1]\n",
      "src_ids is  [17, 53, 2311, 1]\n",
      "src_ids is  [17, 53, 848, 1]\n",
      "src_ids is  [17, 53, 772, 1]\n",
      "src_ids is  [17, 229, 2316, 23, 31, 217, 1446, 1]\n",
      "src_ids is  [289, 37, 117, 2305, 1]\n",
      "src_ids is  [17, 53, 125, 1]\n",
      "src_ids is  [17, 53, 1007, 1192, 1]\n",
      "src_ids is  [17, 53, 2320, 1]\n",
      "src_ids is  [17, 53, 928, 648, 1]\n",
      "src_ids is  [17, 53, 944, 1721, 1]\n",
      "src_ids is  [17, 53, 1131, 2323, 1]\n",
      "src_ids is  [289, 37, 161, 1537, 2326, 1]\n",
      "src_ids is  [17, 2327, 31, 1410, 2236, 2237, 1]\n",
      "src_ids is  [17, 2327, 4, 240, 1198, 2236, 2237, 1]\n",
      "src_ids is  [2329, 1146, 2330, 1]\n",
      "src_ids is  [17, 53, 1383, 1133, 1]\n",
      "src_ids is  [17, 53, 2338, 1]\n",
      "src_ids is  [1430, 1383, 217, 1974, 225, 31, 1170, 787, 1124, 2342, 1]\n",
      "src_ids is  [1430, 1383, 217, 1974, 225, 4, 1470, 2344, 1200, 1]\n",
      "src_ids is  [289, 1045, 1383, 217, 713, 2345, 1]\n",
      "src_ids is  [17, 53, 1389, 1133, 1]\n",
      "src_ids is  [1430, 1389, 217, 1974, 225, 31, 1170, 787, 1124, 2342, 1]\n",
      "src_ids is  [289, 1045, 1389, 217, 713, 2345, 1]\n",
      "src_ids is  [1430, 1389, 217, 1974, 225, 4, 1470, 2344, 1200, 1]\n",
      "src_ids is  [17, 53, 2361, 2362, 1133, 1]\n",
      "src_ids is  [1430, 2361, 2362, 63, 217, 1974, 225, 31, 1170, 787, 1124, 2342, 1]\n",
      "src_ids is  [1430, 2361, 2362, 217, 1974, 225, 4, 1470, 2344, 1200, 1]\n",
      "src_ids is  [289, 1045, 2361, 2362, 217, 713, 2345, 1]\n",
      "src_ids is  [17, 53, 1486, 1133, 1]\n",
      "src_ids is  [1430, 1486, 217, 1974, 225, 31, 1170, 787, 1124, 2342, 1]\n",
      "src_ids is  [1430, 1486, 217, 1974, 225, 4, 1470, 2344, 1200, 1]\n",
      "src_ids is  [289, 1045, 1486, 217, 713, 2345, 1]\n",
      "src_ids is  [289, 810, 1198, 95, 1486, 217, 1433, 37, 151, 4, 1043, 1]\n",
      "src_ids is  [289, 810, 1198, 95, 2361, 2362, 217, 1433, 37, 151, 4, 1043, 1]\n",
      "src_ids is  [289, 810, 1198, 95, 1389, 217, 1433, 37, 151, 4, 1043, 1]\n",
      "src_ids is  [289, 810, 1198, 95, 1383, 217, 1433, 37, 151, 4, 1043, 1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/toonies/anaconda3/lib/python3.9/site-packages/torch/nn/modules/lazy.py:178: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n",
      "  warnings.warn('Lazy modules are a new feature under heavy development '\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (960x2382 and 128x2382)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_8222/43773567.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAttnDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moop_qa\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_8222/655334449.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(train_dataloader, encoder, decoder, n_epochs, learning_rate, print_every, plot_every)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mplot_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8222/3821261267.py\u001b[0m in \u001b[0;36mtrain_epoch\u001b[0;34m(dataloader, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_hidden\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         loss = criterion(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_8222/3746341558.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, encoder_outputs, encoder_hidden, target_tensor)\u001b[0m\n\u001b[1;32m     57\u001b[0m                 \u001b[0mdecoder_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtopi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m         \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m         \u001b[0mdecoder_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecoder_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0mattentions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattentions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1128\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1129\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1130\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1131\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (960x2382 and 128x2382)"
     ]
    }
   ],
   "source": [
    "hidden_size = 128\n",
    "batch_size = 32\n",
    "\n",
    "oop_qa, train_dataloader = get_dataloader(batch_size)\n",
    "\n",
    "encoder = EncoderRNN(oop_qa.n_words, hidden_size).to(device)\n",
    "decoder = AttnDecoderRNN(hidden_size, oop_qa.n_words).to(device)\n",
    "\n",
    "train(train_dataloader, encoder, decoder, 400, print_every=20, plot_every=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, sentence, oop_qa):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(oop_qa, sentence)\n",
    "\n",
    "        encoder_outputs, encoder_hidden = encoder(input_tensor)\n",
    "        decoder_outputs, decoder_hidden, decoder_attn = decoder(encoder_outputs, encoder_hidden)\n",
    "\n",
    "        _, topi = decoder_outputs.topk(1)\n",
    "        decoded_ids = topi.squeeze()\n",
    "\n",
    "        decoded_words = []\n",
    "        for idx in decoded_ids:\n",
    "            if idx.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            decoded_words.append(oop_qa.index2word[idx.item()])\n",
    "    return decoded_words, decoder_attn\n",
    "\n",
    "\n",
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs_return)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, _ = evaluate(encoder, decoder, pair[0], oop_qa)\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> who discovered a complete theorem-proving algorithm for first-order logic in 1965?\n",
      "= J. A. Robinson's\n",
      "\n",
      "< initial pruning space  satisfiable episodic; mechanism concerned sophisticated concerned branching sophisticated sophisticated Complete fit fit concerned branching \"Reduces example branching Goal Complex branching \"Reduces Goal Complex branching \"Reduces Goal\n",
      "\n",
      "> How does logic differs?\n",
      "= Logics differ in their ontological commitments and epistemological commitments.\n",
      "\n",
      "< of representing knowledge base world.\n",
      " <EOS>\n",
      "\n",
      "> What is the right thing?\n",
      "= \"It is expected to maximize goal achievement\n",
      "< \"It is expected to maximize goal achievement <EOS>\n",
      "\n",
      "> What is Five-in-row system?\n",
      "= Five-in-row system is normally is implemented as a board game.\n",
      "\n",
      "< Five-in-row system is higher than by programming its intelligence (AI) problem unary proof they go next.\n",
      " <EOS>\n",
      "\n",
      "> What are the four basic kinds of agent programs that embody the principles underlying almost all intelligent systems?\n",
      "= Simple reflex agents; Model-based reflex agents; Goal-based agents; and Utility-based agents.\n",
      "\n",
      "< Simple reflex agents; Goal-based agents; and Utility-based agents.\n",
      " <EOS>\n",
      "\n",
      "> What task environment makes an agent need not worry about uncertainty?\n",
      "= fully observable and deterministic.\n",
      "\n",
      "< <EOS>\n",
      "\n",
      "> What is semantics?\n",
      "= \"Semantics are the meaning of sentences\n",
      "< \"Semantics are the “solutions.”\n",
      " <EOS>\n",
      "\n",
      "> Who reminded that the field of those broader goals and warned that the subfields were in danger of becoming ends in themselves?\n",
      "= Nils Nilsson (1995)\n",
      "\n",
      "< Nils Nilsson (1995)\n",
      " <EOS>\n",
      "\n",
      "> What are the examples of games of imperfect information?\n",
      "= \"The examples are poker and bridge\n",
      "< SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS SOS\n",
      "\n",
      "> What kind of advances facilitated the big data phenomenon?\n",
      "= Remarkable advances in computing power and the creation of the World Wide Web.\n",
      "\n",
      "< Remarkable for representing uncertain knowledge bases in computing representing uncertain variables or \"Reduces knowledge.\n",
      " \"Reduces Following Equipment \"Reduces Equipment Corporation Equipment \"Reduces Equipment \"Reduces Equipment \"Reduces Equipment \"Reduces \"Recursive symbol\n",
      "\n"
     ]
    }
   ],
   "source": [
    "encoder.eval()\n",
    "decoder.eval()\n",
    "evaluateRandomly(encoder, decoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000, 16])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "max_len = 1000\n",
    "num_hiddens = 32\n",
    "\n",
    "a = torch.arange(max_len, dtype=torch.float32).reshape(-1, 1) / torch.pow(10000, torch.arange(0, num_hiddens, 2, dtype=torch.float32) / num_hiddens)\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([         1,          4,         16,         64,        256,       1024,\n",
       "              4096,      16384,      65536,     262144,    1048576,    4194304,\n",
       "          16777216,   67108864,  268435456, 1073741824,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0,\n",
       "                 0,          0,          0,          0,          0,          0],\n",
       "       dtype=torch.int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.pow(2, torch.arange(0, num_hiddens, 2, dtype=torch.int)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  0.,   1.,   2.,   3.,   4.,   5.,   6.,   7.,   8.,   9.,  10.,  11.,\n",
       "         12.,  13.,  14.,  15.,  16.,  17.,  18.,  19.,  20.,  21.,  22.,  23.,\n",
       "         24.,  25.,  26.,  27.,  28.,  29.,  30.,  31.,  32.,  33.,  34.,  35.,\n",
       "         36.,  37.,  38.,  39.,  40.,  41.,  42.,  43.,  44.,  45.,  46.,  47.,\n",
       "         48.,  49.,  50.,  51.,  52.,  53.,  54.,  55.,  56.,  57.,  58.,  59.,\n",
       "         60.,  61.,  62.,  63.,  64.,  65.,  66.,  67.,  68.,  69.,  70.,  71.,\n",
       "         72.,  73.,  74.,  75.,  76.,  77.,  78.,  79.,  80.,  81.,  82.,  83.,\n",
       "         84.,  85.,  86.,  87.,  88.,  89.,  90.,  91.,  92.,  93.,  94.,  95.,\n",
       "         96.,  97.,  98.,  99., 100., 101., 102., 103., 104., 105., 106., 107.,\n",
       "        108., 109., 110., 111., 112., 113., 114., 115., 116., 117., 118., 119.,\n",
       "        120., 121., 122., 123., 124., 125., 126., 127., 128., 129., 130., 131.,\n",
       "        132., 133., 134., 135., 136., 137., 138., 139., 140., 141., 142., 143.,\n",
       "        144., 145., 146., 147., 148., 149., 150., 151., 152., 153., 154., 155.,\n",
       "        156., 157., 158., 159., 160., 161., 162., 163., 164., 165., 166., 167.,\n",
       "        168., 169., 170., 171., 172., 173., 174., 175., 176., 177., 178., 179.,\n",
       "        180., 181., 182., 183., 184., 185., 186., 187., 188., 189., 190., 191.,\n",
       "        192., 193., 194., 195., 196., 197., 198., 199., 200., 201., 202., 203.,\n",
       "        204., 205., 206., 207., 208., 209., 210., 211., 212., 213., 214., 215.,\n",
       "        216., 217., 218., 219., 220., 221., 222., 223., 224., 225., 226., 227.,\n",
       "        228., 229., 230., 231., 232., 233., 234., 235., 236., 237., 238., 239.,\n",
       "        240., 241., 242., 243., 244., 245., 246., 247., 248., 249., 250., 251.,\n",
       "        252., 253., 254., 255., 256., 257., 258., 259., 260., 261., 262., 263.,\n",
       "        264., 265., 266., 267., 268., 269., 270., 271., 272., 273., 274., 275.,\n",
       "        276., 277., 278., 279., 280., 281., 282., 283., 284., 285., 286., 287.,\n",
       "        288., 289., 290., 291., 292., 293., 294., 295., 296., 297., 298., 299.,\n",
       "        300., 301., 302., 303., 304., 305., 306., 307., 308., 309., 310., 311.,\n",
       "        312., 313., 314., 315., 316., 317., 318., 319., 320., 321., 322., 323.,\n",
       "        324., 325., 326., 327., 328., 329., 330., 331., 332., 333., 334., 335.,\n",
       "        336., 337., 338., 339., 340., 341., 342., 343., 344., 345., 346., 347.,\n",
       "        348., 349., 350., 351., 352., 353., 354., 355., 356., 357., 358., 359.,\n",
       "        360., 361., 362., 363., 364., 365., 366., 367., 368., 369., 370., 371.,\n",
       "        372., 373., 374., 375., 376., 377., 378., 379., 380., 381., 382., 383.,\n",
       "        384., 385., 386., 387., 388., 389., 390., 391., 392., 393., 394., 395.,\n",
       "        396., 397., 398., 399., 400., 401., 402., 403., 404., 405., 406., 407.,\n",
       "        408., 409., 410., 411., 412., 413., 414., 415., 416., 417., 418., 419.,\n",
       "        420., 421., 422., 423., 424., 425., 426., 427., 428., 429., 430., 431.,\n",
       "        432., 433., 434., 435., 436., 437., 438., 439., 440., 441., 442., 443.,\n",
       "        444., 445., 446., 447., 448., 449., 450., 451., 452., 453., 454., 455.,\n",
       "        456., 457., 458., 459., 460., 461., 462., 463., 464., 465., 466., 467.,\n",
       "        468., 469., 470., 471., 472., 473., 474., 475., 476., 477., 478., 479.,\n",
       "        480., 481., 482., 483., 484., 485., 486., 487., 488., 489., 490., 491.,\n",
       "        492., 493., 494., 495., 496., 497., 498., 499., 500., 501., 502., 503.,\n",
       "        504., 505., 506., 507., 508., 509., 510., 511., 512., 513., 514., 515.,\n",
       "        516., 517., 518., 519., 520., 521., 522., 523., 524., 525., 526., 527.,\n",
       "        528., 529., 530., 531., 532., 533., 534., 535., 536., 537., 538., 539.,\n",
       "        540., 541., 542., 543., 544., 545., 546., 547., 548., 549., 550., 551.,\n",
       "        552., 553., 554., 555., 556., 557., 558., 559., 560., 561., 562., 563.,\n",
       "        564., 565., 566., 567., 568., 569., 570., 571., 572., 573., 574., 575.,\n",
       "        576., 577., 578., 579., 580., 581., 582., 583., 584., 585., 586., 587.,\n",
       "        588., 589., 590., 591., 592., 593., 594., 595., 596., 597., 598., 599.,\n",
       "        600., 601., 602., 603., 604., 605., 606., 607., 608., 609., 610., 611.,\n",
       "        612., 613., 614., 615., 616., 617., 618., 619., 620., 621., 622., 623.,\n",
       "        624., 625., 626., 627., 628., 629., 630., 631., 632., 633., 634., 635.,\n",
       "        636., 637., 638., 639., 640., 641., 642., 643., 644., 645., 646., 647.,\n",
       "        648., 649., 650., 651., 652., 653., 654., 655., 656., 657., 658., 659.,\n",
       "        660., 661., 662., 663., 664., 665., 666., 667., 668., 669., 670., 671.,\n",
       "        672., 673., 674., 675., 676., 677., 678., 679., 680., 681., 682., 683.,\n",
       "        684., 685., 686., 687., 688., 689., 690., 691., 692., 693., 694., 695.,\n",
       "        696., 697., 698., 699., 700., 701., 702., 703., 704., 705., 706., 707.,\n",
       "        708., 709., 710., 711., 712., 713., 714., 715., 716., 717., 718., 719.,\n",
       "        720., 721., 722., 723., 724., 725., 726., 727., 728., 729., 730., 731.,\n",
       "        732., 733., 734., 735., 736., 737., 738., 739., 740., 741., 742., 743.,\n",
       "        744., 745., 746., 747., 748., 749., 750., 751., 752., 753., 754., 755.,\n",
       "        756., 757., 758., 759., 760., 761., 762., 763., 764., 765., 766., 767.,\n",
       "        768., 769., 770., 771., 772., 773., 774., 775., 776., 777., 778., 779.,\n",
       "        780., 781., 782., 783., 784., 785., 786., 787., 788., 789., 790., 791.,\n",
       "        792., 793., 794., 795., 796., 797., 798., 799., 800., 801., 802., 803.,\n",
       "        804., 805., 806., 807., 808., 809., 810., 811., 812., 813., 814., 815.,\n",
       "        816., 817., 818., 819., 820., 821., 822., 823., 824., 825., 826., 827.,\n",
       "        828., 829., 830., 831., 832., 833., 834., 835., 836., 837., 838., 839.,\n",
       "        840., 841., 842., 843., 844., 845., 846., 847., 848., 849., 850., 851.,\n",
       "        852., 853., 854., 855., 856., 857., 858., 859., 860., 861., 862., 863.,\n",
       "        864., 865., 866., 867., 868., 869., 870., 871., 872., 873., 874., 875.,\n",
       "        876., 877., 878., 879., 880., 881., 882., 883., 884., 885., 886., 887.,\n",
       "        888., 889., 890., 891., 892., 893., 894., 895., 896., 897., 898., 899.,\n",
       "        900., 901., 902., 903., 904., 905., 906., 907., 908., 909., 910., 911.,\n",
       "        912., 913., 914., 915., 916., 917., 918., 919., 920., 921., 922., 923.,\n",
       "        924., 925., 926., 927., 928., 929., 930., 931., 932., 933., 934., 935.,\n",
       "        936., 937., 938., 939., 940., 941., 942., 943., 944., 945., 946., 947.,\n",
       "        948., 949., 950., 951., 952., 953., 954., 955., 956., 957., 958., 959.,\n",
       "        960., 961., 962., 963., 964., 965., 966., 967., 968., 969., 970., 971.,\n",
       "        972., 973., 974., 975., 976., 977., 978., 979., 980., 981., 982., 983.,\n",
       "        984., 985., 986., 987., 988., 989., 990., 991., 992., 993., 994., 995.,\n",
       "        996., 997., 998., 999.])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(1000, dtype = torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 0, 0]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "nums = [0,0,1]\n",
    "temp_num = nums.copy()\n",
    "for num in nums:\n",
    "    if num == 0:\n",
    "        nums.remove(num)\n",
    "        nums.append(0)\n",
    "\n",
    "nums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionWiseFFN(nn.Module):\n",
    "    def __init__(self, ffn_num_hiddens, ffn_num_outputs):\n",
    "        super().__init__()\n",
    "        self.dense1 = nn.LazyLinear(ffn_num_hiddens)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense2 = nn.LazyLinear(ffn_num_outputs)\n",
    "\n",
    "    def forward(self, X):\n",
    "        return self.dense2(self.relu(self.dense1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4076,  0.0295, -0.1874, -0.3984, -0.2571, -0.1063, -0.5304, -0.1125],\n",
       "        [-0.4076,  0.0295, -0.1874, -0.3984, -0.2571, -0.1063, -0.5304, -0.1125],\n",
       "        [-0.4076,  0.0295, -0.1874, -0.3984, -0.2571, -0.1063, -0.5304, -0.1125]],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ffn = PositionWiseFFN(4, 8)\n",
    "ffn.eval()\n",
    "ffn(torch.ones((2,3,4)))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddNorm(nn.Module):\n",
    "    def __init__(self, norm_shape, dropout):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.ln = nn.LayerNorm(norm_shape)\n",
    "\n",
    "    def forward(self, X, Y):\n",
    "        return self.ln(self.dropout(Y) + X)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add_norm = AddNorm(4, 0.5)\n",
    "shape = (2, 3, 4)\n",
    "add_norm(torch.ones(shape), torch.ones(shape)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00:20:22\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Chuỗi thời gian\n",
    "time_string = \"12:20:22AM\"\n",
    "\n",
    "\n",
    "\n",
    "def timeConversion(s):\n",
    "    # Write your code here\n",
    "    time_convert = lambda h: f\"{h:02d}\"\n",
    "    meridiem = re.findall(\"AM|PM\", s)\n",
    "    hour = int(re.findall(\"^(\\d{2})\", s)[0])\n",
    "    if meridiem[0] == \"PM\":\n",
    "        if hour < 12:\n",
    "            s = re.sub(\"^(\\d{2})\", time_convert(hour+12),s)\n",
    "    else:\n",
    "        if hour >= 12:\n",
    "            s = re.sub(\"^(\\d{2})\", time_convert(hour-12),s)\n",
    "\n",
    "            \n",
    "    return re.findall(\"\\d{2}:\\d{2}:\\d{2}\", s)[0]\n",
    "\n",
    "print(timeConversion(time_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12:20:22']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_string = \"12:20:22PM\"\n",
    "\n",
    "re.findall(\"\\d{2}:\\d{2}:\\d{2}\", time_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['<cls>', 'This', 'is', 'the', 'first', 'sentence', '<sep>', 'This', 'is', 'the', 'second', 'sentence', '<sep>', 'This', 'is', 'the', 'third', 'sentence', '<sep>']\n",
      "Segments: [0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "def get_tokens_and_segments(token_lists):\n",
    "    \"\"\"Get tokens of the BERT input sequence and their segment IDs.\"\"\"\n",
    "    tokens = ['<cls>']\n",
    "    segments = [0]\n",
    "\n",
    "    for idx, token_list in enumerate(token_lists):\n",
    "        tokens += token_list + ['<sep>']\n",
    "        segments += [idx % 2] * (len(token_list) + 1)\n",
    "\n",
    "    return tokens, segments\n",
    "\n",
    "# Sử dụng hàm với một danh sách các danh sách tokens\n",
    "tokens_a = ['This', 'is', 'the', 'first', 'sentence']\n",
    "tokens_b = ['This', 'is', 'the', 'second', 'sentence']\n",
    "tokens_c = ['This', 'is', 'the', 'third', 'sentence']\n",
    "\n",
    "all_tokens = [tokens_a, tokens_b, tokens_c]\n",
    "\n",
    "tokens, segments = get_tokens_and_segments(all_tokens)\n",
    "\n",
    "print(\"Tokens:\", tokens)\n",
    "print(\"Segments:\", segments)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13 (main, Aug 25 2022, 23:26:10) \n[GCC 11.2.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "0537a1d653c093fb02d1293095f59a9c228f06e915f323afd8901f156f0a590c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
